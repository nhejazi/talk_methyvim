---
title: "Data-Adaptive Estimation and Inference for Differential Methylation Analysis"
subtitle: "The _`methyvim`_ R Package"
author: "[Nima Hejazi](https://statistics.berkeley.edu/~nhejazi)"
insitution: "University of California, Berkeley"
date: "`r lubridate::round_date(lubridate::now(), unit = 'day')`"
bibliography: references.bib
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      navigation: {
        scroll: false
      }
---

```{r knitr_setup, echo=FALSE, message=FALSE}
knitr::opts_chunk$set(fig.width = 7, fig.height = 4.5, dpi = 300,
                      fig.cap = "", fig.align = "center")
showtext::showtext_opts(dpi = 300)
```

```{r optoins_setup, include=FALSE}
options(htmltools.dir.version = FALSE)
options(scipen = 999)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
solarized_light(
  #base_color = "#1c5253",
  header_font_google = google_font("Josefin Sans"),
  text_font_google = google_font("Montserrat", "300", "300i"),
  code_font_google = google_font("Droid Mono")
)
```

```{r refmanager, load_refs, echo=FALSE, cache=FALSE}
library(RefManageR)
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           first.inits = TRUE,
           dashed = TRUE,
           max.names = 3,
           cite.style = 'alphabetic',
           style = "markdown",
           hyperlink = FALSE,
           dashed = FALSE)
methyvim_bib <- ReadBib("./references.bib", check = FALSE)
NoCite(methyvim_bib)
```

# Preview: Summary

* DNA methylation data is _extremely_ high-dimensional -- we can
  collect data on 850K genomic sites with modern arrays!

* Normalization and QC are critical components of properly analyzing
  modern DNA methylation data. There are many choices of technique.

* A relative scarcity of techniques for estimation and inference exists
  -- analyses are often limited to the general linear model.

* Statistical causal inference provides an avenue for answering richer
  scientific questions, especially when combined with modern advances in
  machine learning.

???

- This slide deck is for a brief (10-15 minute) talk on a recently developed
   statistical methodology for using data-adaptive estimates of nonparametric
   variable importance measures for differential methylation analysis. This talk
   was most recently given at [BioC 2018](https://bioc2018.bioconductor.org),
   the annual meeting of the [Bioconductor project](https://bioconductor.org),
   in Toronto, ON, Canada, in July 2018.

- We'll go over this summary again at the end of the talk. Hopefully, it will all
   make more sense then.

---

# Let's meet the data

* Observational study of the impact of disease state on DNA methylation:

  1. $n = 216$ subjects;
  2. Binary disease status: Fetal Alcohol Spectrum Disorders (FASD);
  3. Potential phenotype-level confounders: sex, age, etc.;
  4. $\sim 850,000$ CpG sites interrogated (Illumina_Infinium MethylationEPIC BeadChip_)

* __Questions__: How, if at all, does disease status affect differential
  methylation? Is a coherent biomarker-type signature detectable?

???

* We're interested in exposing/understanding a potential mechanistic interplay
  between disease status and DNA methylation.

* In particular, we'd like to construct some kind of importance score for
  CpG sites impacted by the exposure/disease of interest.

* Dimensionality is a problem, c.f., RNA-seq analyses are $\sim 30,000$ in
  dimension at the gene level.

---

# Data Analysis?

* __First pass:__ For each CpG site $g = 1, \ldots, G$, fit a linear model:
  $$\mathbb{E}[y_g] = X \beta_g$$

* Test the coefficent of interest using a standard t-test:
  $$t_{g} = \frac{\hat{\beta}_{g} - \beta_{g, H_0}}{s_g}$$

* Convenience models: does $\hat{\beta}_{g}$ answer our scientific questions?
  Perhaps not.

* Modern biotechnology, so why not use modern statistics? Machine learning?
  Statistical inference?

???

* CpG sites are thought to function in groups. Treating them as acting
  independently is _not_ faithful to the underlying biology.

* The linear model is a great starting point for analyses when the data is
  generated using complex technology -- no need to make the analysis more
  complicated, at least for a first pass.

* That being said, the data is difficult and expensive to collect, so why
  restrict the scope of the questions we'd like to ask.

---

# Science Before Statistics

* __Question:__ What is the effect of disease status on DNA methylation at a
  specific CpG site, controlling for the observed methylation status of the
  neighbors of the given CpG site?

* Treating CpG sites as acting independently is _not_ faithful to the underlying
  biology.

* We should take into account the methylation status of neighboring CpG sites
  when assessing differential methylation at a single site.

---

# A Data-Adaptive Approach

* Isolate a subset of CpG sites for which there is cursory evidence of
  differential methylation.

* Assign CpG sites into neighborhoods (e.g., base pair distance). If there are
  many neighbors, apply clustering (e.g., _PAM_) to select a subset.

* Estimate a _variable importance measure_ (VIM) at each CpG site, with disease
  as intervention $A$ and controlling for neighboring CpG sites $W$.

* Apply a variant of the Benjamini & Hochberg procedure to control FDR even when
  initial screening is applied.

???

* Pre-screening is a critical step since we cannot perform computationally
  intensive estimation on all the sites. This is flexible -- just use your
  favorite method (as long as allows a ranking to be made).

* The variable importance step merely comes down to the creation of a score. We
  use TMLE to statistically estimate target parameters from causal models. The
  procedure is general enough to accommodate any inferential technique.

---

# Pre-Screening

* The estimation procedure is computationally intensive -- apply it only
  to sites that appear promising.

* Consider estimating univariate (linear) regressions of intervention on
  CpG methylation status. Why? Fast and easy.

* Select CpG sites with a marginal p-value (of $\beta$) below, say, $0.01$.
  Apply data-adaptive procedure to this subset.

* Modeling assumptions irrelevant: this is not the statistical model we will use
  for inference.

???

* Software implementation is open source and easily extensible -- can use any
  algorithm you like for filtering.

* We'll be adding to the available routines for pre-screening too! For now, we
  have [`limma`](https://bioconductor.org/packages/limma).

---

# Too many neighbors?

* With limited sample sizes, the number of neighboring sites that may be
  controlled for is limited.

* To faithfully answer the question of interest, choose the neighboring
  sites that are the most representative.

* Generate a limited set of clusters and choose the CpG sites at the center of
  these clusters as representative of the set of neighbors.

* For convenience, we use PAM: __P__artitioning __A__round __M__edoids.

* Nihilistic much? __An Impossiblity Theorem for Clustering__ (NIPS 2002).

* This is an _optional_ step -- only applied when set of neighbors is large.


???

* The number of sites that we can control for is roughly a function of
  sample size. This impacts the definition of the parameter that we estimate,
  and allows enough flexibility to obtain either very local or more regional
  estimates.

---

# NP Variable Importance

* A simple target causal parameter: the average treatment effect (ATE):
  $$\Psi_g(P_0) = \mathbb{E}_{W,0}[\mathbb{E}_0[Y_g \mid A = a_1, W_{-g}] - \mathbb{E}_0[Y_g \mid A = a_0, W_{-g}]]$$

* A _nonparametric_ measure of how methylation at CpG sites is impacted by a
  discrete intervention.

* The choice of target parameter is flexible -- let it be determined by our
  scientific question of interest.

* We use _targeted minimum loss-based estimation_ (TMLE), for statistical
  inference in infinite-dimensional statistical models.

* Using TML estimators allows for machine learning to be incorporated into the
  estimation of nuisance parameters.

???

* _Interpretation:_ The average difference in methylation at CpG site $g$
  between a setting where all units receive intervention $a_1$ and, possibly
  contrary-to-fact, the setting where all units receive intervention $a_0$,
  controlling for possible confounding from neighboring sites.

* By allowing scientific questions to inform the parameters that we choose
  to estimate, we can do a better job of actually answering the questions of
  interest to our collaborators. Further, we abandon the need to specify the
  functional relationship between our outcome and covariates; moreover, we
  can now make use of advances in machine learning.

---

# Properties of TMLEs

* No need to specify a functional form or make assumptions about the true
  data-generating process.

* Use ensemble machine learning (through cross-validation) to estimate
  constituent parts (nuisance parameters) of TML estimators.

* __Asymptotic linearity__ (of NP estimator)**:**
  $$\Psi_g(P_n^*) - \Psi_g(P_0) = \frac{1}{n} \sum_{i = 1}^{n} \text{EIF}(O_i) + o_P\left(\frac{1}{\sqrt{n}}\right)$$

* __Limiting distribution:__
  $$\sqrt{n}(\Psi_g(P_n^*) - \Psi_g(P_0)) \to N(0, \text{Var(EIF)})$$

* __Statistical inference:__
  $$\Psi_g(P_n^*) \pm z_{1 - \alpha} \cdot \sqrt{\frac{\text{Var(EIF)}}{n}}$$

???

Under the additional condition that the remainder term $R(\hat{P}^*, P_0)$
decays as $o_P \left( \frac{1}{\sqrt{n}} \right)$, we have that
$\Psi_n - \Psi_0 = (P_n - P_0) \cdot D(P_0) + o_P \left( \frac{1}{\sqrt{n}} \right)$,
which, by a central limit theorem,
establishes a Gaussian limiting distribution for the estimator, with variance
$V(D(P_0))$, the variance of the efficient influence curve (canonical gradient)
when $\Psi$ admits an asymptotically linear representation.

The above implies that $\Psi_n$ is a $\sqrt{n}$-consistent estimator of $\Psi$,
that it is asymptotically normal (as given above), and that it is locally
efficient. This allows us to build Wald-type confidence intervals, where
$\sigma_n^2$ is an estimator of $V(D(P_0))$. The estimator $\sigma_n^2$
may be obtained using the bootstrap or computed directly via
$\sigma_n^2 = \frac{1}{n} \sum_{i = 1}^{n} D^2(\bar{Q}_n^*, g_n)(O_i)$

---

# Multiple Testing `r emo::ji('sad')`

* Multiple testing corrections are critical. Without these, we
  systematically obtain misleading results.

* The Benjamini & Hochberg procedure for controlling the False Discovery
  Rate (FDR) is a well-established technique for addressing the multiple
  testing issue.

* We use a modified BH-FDR procedure to account for the pre-screening step
  of the proposed algorithm.

* This modified BH-FDR procedure for multi-stage analyses (FDR-MSA) works
  by adding a p-value of $1.0$ for each site that did not pass pre-screening
  then performs BH-FDR as normal.

???

* Note that $\text{FDR} = \mathbb{E}\left[\frac{V}{R}\right] = \mathbb{E}\left[\frac{V}{R} \mid R > 0 \right] P(R > 0)$.

* BH-FDR procedure: Find $\hat{k} = max\{k: p_{(k)} \leq \frac{k}{M} \cdot \alpha\}$

* FDR-MSA will only incur a loss of power if the initial screening
  excludes variables that would have been rejected by the BH procedure when
  applied to the subset on which estimation was performed.

* BH-FDR control is a rank-based procedure, so we must assume that the
  pre-screening does not disrupt the ranking with respect to the estimation
  subset, which is provably true for screening procedures of a given type.

* MSA controls type I error with any procedure that is a function of only
  the type I error itself --- e.g., FWER. This does not hold for the FDR in
  complete generality.

---

# R/`methyvim`

* Exposes this variable importance methodology for a causal parameter for
  discrete interventions.

* Soon to support a causal parameter that handles continuous interventions.

* Take it for a test drive!

* Stable release: https://bioconductor.org/packages/methyvim

* Development version: https://github.com/nhejazi/methyvim

* Documentation: https://code.nimahejazi.org/methyvim

???

* Contribute on GitHub: https://github.com/nhejazi/methyvim

* Reach out to us with questions and feature requests.

---

# Future Work

* Combining estimates of the positional importance (DMP) of CpG sites into
  estimates and statistical inference for region discovery (DMR).

* Enhanced interoperability with existing methodology and packages (e.g.,
  `minfi`, `DelayedArray`).

* Consideration of and extension to alternative data types (e.g., RRBS).

---

# Acknowledgements

<u>Science doesn't happen alone</u>:

* University of California, Berkeley:
  * Advisors: Mark J. van der Laan and Alan E. Hubbard
  * Colleagues: Rachael V. Phillips
  * Collaborations: Labs of Martyn T. Smith and Nina T. Holland

* Funding source (NIH):
  * National Library of Medicine: T32-LM012417-02
  * National Institute of Environmental Health Sciences: R01 ES021369-05
  * National Institute of Environmental Health Sciences: P42 ES004705-29

* Thanks for your time `r emo::ji('thanks')`

---

# Selected References

```{r, 'refs', results='asis', echo=FALSE}
PrintBibliography(methyvim_bib)
```

---

# Review: Summary

* DNA methylation data is _extremely_ high-dimensional -- we can
  collect data from 850K to millions of CpG sites with modern assays!

* Normalization and QC are critical components of properly analyzing
  modern DNA methylation data. There are many choices of technique.

* A relative scarcity of techniques for estimation and inference exists
  -- analyses are often limited to (generalized) linear models.

* Developments in statistical causal inference may be leveraged to answer richer
  scientific questions about DNA methylation.

* Advances in machine learning may be used to add flexibility to our causal
  inference approaches.

* __Source:__ https://github.com/nhejazi/talk_methyvim

* __Slides:__ https://bit.ly/bioc_methyvim_2018

???

Hopefully, this all makes a bit more sense now.

